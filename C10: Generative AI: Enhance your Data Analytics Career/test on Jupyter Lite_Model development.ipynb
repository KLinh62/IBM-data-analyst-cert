{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod2.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Reading the data set and generating the statistical description",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:**\n<br>Write a python code to perform the following actions.\n1. Import a data set from a CSV file, The headers for the data set must be in the first row of the CSV file.\n2. Generate the statistical description of all the features used in the data set. Include \"object\" data types as well.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\nimport pandas as pd\n\n# 1. Import a data set from a CSV file\ndata = pd.read_csv('dataset.csv')\n\n# 2. Generate the statistical description of all the features\ndescription = data.describe(include='all')\n\nprint(description)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Creating parameter visualizations",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:**\n<br>Write a Python code to perform the following actions.\n1. Create regression plots for the attributes \"CPU_frequency\", \"Screen_Size_inch\" and \"Weight_pounds\" against \"Price\".\n2. Create box plots for the attributes \"Category\", \"GPU\", \"OS\", \"CPU_core\", \"RAM_GB\" and \"Storage_GB_SSD\" against the attribute \"Price\".",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "# 1. Create regression plots\nregression_attributes = [\"CPU_frequency\", \"Screen_Size_inch\", \"Weight_pounds\"]\n\nfor attribute in regression_attributes:\n    plt.figure(figsize=(10,6))\n    sns.regplot(x=\"Price\", y=attribute, data=data, marker=\"o\", label=attribute)\n    plt.title(f\"Regression plot for {attribute} against Price\")\n    plt.xlabel(\"Price\")\n    plt.ylabel(\"Value\")\n    plt.legend()\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# 2. Create box plots\nboxplot_attributes = [\"Category\", \"GPU\", \"OS\", \"CPU_core\", \"RAM_GB\", \"Storage_GB_SSD\"]\n\nfor attribute in boxplot_attributes:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"Price\", y=attribute, data=data)\n    plt.title(f\"Box plot for {attribute} against Price\")\n    plt.xlabel(\"Price\")\n    plt.ylabel(\"Value\")\n    plt.show()",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Evaluate dependence",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:**\n<br>Write a Python code for the following.\n1. Evaluate the correlation value, pearson coefficient and p-values for all numerical attributes against the target attribute \"Price\".\n2. Don't include the values evaluated for target variable against itself.\n3. Print these values as a part of a single dataframe against each individual attrubute.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy.stats import pearsonr",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "# Assuming your dataframe has a target attribute 'Price'\ndf = pd.read_csv('dataset.csv')\n\n# Select numerical attributes\nnumerical_attributes = df.select_dtypes(include=np.number)\n\n# Calculate correlation values for all numerical attributes against 'Price'\ncorrelation_values = numerical_attributes.corr()['Price'].drop('Price')\n\n# Calculate Pearson coefficient and p-values for all numerical attributes against 'Price'\npearson_coefficients = []\np_values = []\n\nfor column in numerical_attributes.columns:\n    if column != 'Price':\n        pearson_coefficient, p_value = pearsonr(numerical_attributes[column], df['Price'])\n        pearson_coefficients.append(pearson_coefficient)\n        p_values.append(p_value)\n\n# Create a new dataframe to store the results\nresults_df = pd.DataFrame({'Attribute': correlation_values.index, 'Correlation Value': correlation_values, 'Pearson Coefficient': pearson_coefficients, 'P-value': p_values})\n\n# Print the results\nprint(results_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                         Attribute  Correlation Value  Pearson Coefficient  \\\nUnnamed: 0.1          Unnamed: 0.1           0.321933             0.321933   \nUnnamed: 0              Unnamed: 0           0.321933             0.321933   \nCategory                  Category           0.286243             0.286243   \nGPU                            GPU           0.288298             0.288298   \nOS                              OS          -0.221730            -0.221730   \nCPU_core                  CPU_core           0.459398             0.459398   \nScreen_Size_inch  Screen_Size_inch          -0.110644            -0.110644   \nCPU_frequency        CPU_frequency           0.366666             0.366666   \nRAM_GB                      RAM_GB           0.549297             0.549297   \nStorage_GB_SSD      Storage_GB_SSD           0.243421             0.243421   \nWeight_pounds        Weight_pounds          -0.050312            -0.050312   \nScreen-Full_HD      Screen-Full_HD          -0.021075            -0.021075   \nScreen-IPS_panel  Screen-IPS_panel           0.021075             0.021075   \n\n                       P-value  \nUnnamed: 0.1      3.851058e-07  \nUnnamed: 0        3.851058e-07  \nCategory          7.225696e-06  \nGPU               6.166950e-06  \nOS                5.696643e-04  \nCPU_core          7.912950e-14  \nScreen_Size_inch  8.853398e-02  \nCPU_frequency     5.502463e-09  \nRAM_GB            3.681561e-20  \nStorage_GB_SSD    1.489892e-04  \nWeight_pounds     4.397694e-01  \nScreen-Full_HD    7.463568e-01  \nScreen-IPS_panel  7.463568e-01  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Grouping and pivots",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:**\n<br>Write a python code that performs the following actions.\n1. Group the attributes \"GPU\", \"CPU_core\" and \"Price\", as available in a dataframe df\n2. Create a pivot table for this group, assuming the target variable to be 'Price' and aggregation function as mean\n3. Plot a pcolor plot for this pivot table.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import the data set as a pandas DataFrame\ndf = pd.read_csv('dataset.csv')\n\n# Group the attributes\ngrouped_data = df.groupby(['GPU', 'CPU_core'])['Price'].mean()\n\n# Create a pivot table\npivot_table = pd.pivot_table(df, values='Price', index='GPU', columns='CPU_core', aggfunc='mean')\n\n# Plot a pcolor plot\nplt.pcolor(pivot_table, cmap='RdBu')\nplt.colorbar()\nplt.title('Pivot Table - Mean Price')\nplt.xlabel('CPU Core')\nplt.ylabel('GPU')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 5. Models Development\n\n### A. Linear regression in one variable\nYou can now ask the generative AI model to generate a script to create a linear regression model using a single attribute as the training feature to predict a target attribute.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Importing data set",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import a data set from a CSV file\ndf = pd.read_csv('dataset.csv')\n\n# Display the first few rows of the data frame\nprint(df.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "   Unnamed: 0.1  Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  \\\n0             0           0         Acer         4    2   1         5   \n1             1           1         Dell         3    1   1         3   \n2             2           2         Dell         3    1   1         7   \n3             3           3         Dell         4    2   1         5   \n4             4           4           HP         4    2   1         7   \n\n   Screen_Size_inch  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_pounds  \\\n0              14.0       0.551724       8             256        3.52800   \n1              15.6       0.689655       4             256        4.85100   \n2              15.6       0.931034       8             256        4.85100   \n3              13.3       0.551724       8             128        2.69010   \n4              15.6       0.620690       8             256        4.21155   \n\n   Price Price-binned  Screen-Full_HD  Screen-IPS_panel  \n0    978          Low               0                 1  \n1    634          Low               1                 0  \n2    946          Low               1                 0  \n3   1244          Low               0                 1  \n4    837          Low               1                 0  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:** <br>\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Build a linear regression model for the data set that uses *CPU_frequency* and source variable and *Price* as the target variable.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "# Extract the source variable and target variable from df\nX = df[['CPU_frequency']]\ny = df['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nmodel = LinearRegression()  # Initialize a linear regression model\nmodel.fit(X_train, y_train) # Train the model\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Calculate and display the Mean Squared Error (MSE) and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Display the MSE and R^2 values\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"R^2 Score:\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error (MSE): 239035.99429436037\nR^2 Score: -0.03719417833496452\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "### B. Linear regression in multiple variables",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:** <br>\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses some attributes of a data frame as the source variables and one of the attributes as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Build a linear regression model for the data set that uses *CPU_frequency, RAM_GB, Storage_GB_SSD, CPU_core, OS, GPU* and *Category* and source variables and *Price* as the target variable.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#import pandas as pd\n#from sklearn.model_selection import train_test_split\n#from sklearn.linear_model import LinearRegression\n#from sklearn.metrics import mean_squared_error, r2_score\n\n# Extract the source variable and target variable from df\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Calculate and display the Mean Squared Error (MSE) and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"R^2 Score:\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error (MSE): 168575.62043820194\nR^2 Score: 0.268538394630248\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "### C. Polynomial regression\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can explore creating a model that uses higher-order features from original attributes. Higher orders of the same feature allow better generalization on the target variable. It is called polynomial regression, and you can use Generative AI to create a code for this.\n\nAssume you are given a single attribute as the source variable and one as a target variable. You must create a model using polynomial regression for a given order. You can also make the model for different order values and compare their performance based on MSE and R^2 scores.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:** <br>\nWrite a Python code that performs the following tasks.\n1. Develops and trains multiple polynomial regression models, with orders 2, 3, and 5, that use one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained models.\n3. Compare the performance of the models.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "=> Try to run the generated code on the testing interface with the source variable as *CPU frequency* and the target variable as *Price*.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#import pandas as pd\n#from sklearn.model_selection import train_test_split\n#from sklearn.linear_model import LinearRegression\n#from sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Extract the source variable and target variable from df\nX = df[['CPU_frequency']]\ny = df['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize lists to store the MSE and R^2 values for each model\nmse_values = []\nr2_values = []\n\n# Create and train polynomial regression models with different orders\norders = [2, 3, 5]\nfor order in orders:\n    poly_features = PolynomialFeatures(degree=order)\n    X_train_poly = poly_features.fit_transform(X_train)\n    X_test_poly = poly_features.transform(X_test)\n    \n    model = LinearRegression() # Initialize a linear regression model\n    model.fit(X_train_poly, y_train) # Train the model\n    \n    y_pred = model.predict(X_test_poly) # Make predictions using the trained model\n\n    # Calculate the MSE and R^2 values\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    # Append the MSE and R^2 values to the lists\n    mse_values.append(mse)\n    r2_values.append(r2)\n\n    # Display the MSE and R^2 values for the current model\n    print(f\"Polynomial Regression Model with Order {order}:\")\n    print(\"Mean Squared Error (MSE):\", mse)\n    print(\"R^2 Score:\", r2)\n    print()\n\n# Compare the performance of the models\nbest_order = np.argmin(mse_values)\nworst_order = np.argmax(r2_values)\n\nprint(\"Model Comparison:\")\nprint(f\"Best Polynomial Order: {best_order + 2}\")\nprint(f\"Worst Polynomial Order: {worst_order + 2}\")\n",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Polynomial Regression Model with Order 2:\nMean Squared Error (MSE): 196263.56145770708\nR^2 Score: 0.14839844951324532\n\nPolynomial Regression Model with Order 3:\nMean Squared Error (MSE): 205918.03020817842\nR^2 Score: 0.10650702302550674\n\nPolynomial Regression Model with Order 5:\nMean Squared Error (MSE): 207335.703609638\nR^2 Score: 0.10035563731845087\n\nModel Comparison:\nBest Polynomial Order: 2\nWorst Polynomial Order: 2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "### D. Creating a Pipeline\nPipelines are processes containing a sequence of steps that lead to creating a trained model.\n\nYou will now use the Generative AI model to create a pipeline for performing feature scaling, creating polynomial features for multiple attributes, and performing linear regression using these variables.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:** <br>\nWrite a Python code that performs the following tasks.\n1. Create a pipeline that performs parameter scaling, Polynomial Feature generation, and Linear regression. Use the set of multiple features as before to create this pipeline.\n2. Calculate and display the MSE and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#import pandas as pd\n#import numpy as np\n#from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\n#from sklearn.linear_model import LinearRegression\n#from sklearn.metrics import mean_squared_error, r2_score\n\n# Extract the source variable and target variable from df\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Create a pipeline for parameter scaling, polynomial feature generation, and linear regression\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('poly_features', PolynomialFeatures(degree=2)),\n    ('linear_regression', LinearRegression())\n])\n\n# Fit the pipeline on the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = pipeline.predict(X_test)\n\n# Calculate mean squared error and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Display the MSE and R^2 values\nprint(\"Mean Squared Error:\", mse)\nprint(\"R^2 Score:\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 5.8233546511535945e+31\nR^2 Score: -2.1798465462279193e+26\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "### E. Grid search and Ridge regression\nAn improved way to train your model is to use **ridge regression** instead of linear regression. You can use the polynomial features of multiple attributes. One of the key factors of ridge regression is using the parameter __*alpha*__ as a hyperparameter for training. \n\nUsing **grid search**, one can determine the optimum value of the hyperparameter for the given set of features. Grid search also uses cross-validation training to train and prepare the optimum model.\n\nYou can use generative AI to create the Python code to perform a grid search for the optimum ridge regression model, which uses polynomial features generated from multiple parameters.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Prompt:** <br>\nWrite a Python code that performs the following tasks.\n1. Use polynomial features for some of the attributes of a data frame.\n2. Perform Grid search on a ridge regression model for a set of values of hyperparameter alpha and polynomial features as input.\n3. Use cross-validation in the Grid search.\n4. Evaluate the resulting model's MSE and R^2 values.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "=> You make use of the following parametric values for this purpose.\n\n**Source Variables**: *CPU_frequency, RAM_GB, Storage_GB_SSD, CPU_core, OS, GPU* and *Category* <br>\n**Target Variable**: *Price* <br>\n**Set of values for alpha**: 0.0001,0.001,0.01, 0.1, 1, 10 <br>\n**Cross Validation**: 4-fold <br>\n**Polynomial Feature order**: 2 <br>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#import pandas as pd\n#from sklearn.preprocessing import PolynomialFeatures\n#from sklearn.pipeline import Pipeline\n#from sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import Ridge\n\n# Extract the source variable and target variable from df\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Create a pipeline for polynomial feature generation and Ridge regression\npipeline = Pipeline([\n    ('poly_features', PolynomialFeatures()),\n    ('ridge_regression', Ridge())\n])\n\n# Define the hyperparameters for Grid Search\nparam_grid = {\n    'poly_features__degree': [2],\n    'ridge_regression__alpha': [0.0001,0.001,0.01, 0.1, 1, 10]\n}\n\n# Perform Grid Search with cross-validation\ngrid_search = GridSearchCV(pipeline, param_grid, cv=4, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)\n\n# Get the best model from Grid Search\nbest_model = grid_search.best_estimator_\n\n# Make predictions on the test set\ny_pred = best_model.predict(X_test)\n\n# Calculate mean squared error and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Display the MSE and R^2 values\nprint(\"Mean Squared Error:\", mse)\nprint(\"R^2 Score:\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 181318.62434867656\nR^2 Score: 0.32127304495362896\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright Â© 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}